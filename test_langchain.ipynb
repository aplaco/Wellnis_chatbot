{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: BNB_CUDA_VERSION=122 environment variable detected; loading libbitsandbytes_cuda122.so.\n",
      "This can be used to load a bitsandbytes version built with a CUDA version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alpaco/anaconda3/envs/fast_langch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.6.2: Fast Llama patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090. Num GPUs = 1. Max memory: 23.691 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "# Unsloth 라이브러리에서 FastLanguageModel을 임포트\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 2048 # 최대 시퀀스 길이를 설정 ( 텍스트의 최대 길이를 지정)\n",
    "dtype = None  # 자동 감지를 위해 None 설정. Tesla T4는 Float16, Ampere+는 Bfloat16 사용. 모델의 파라미터를 저장할 데이터 타입\n",
    "load_in_4bit = True  # 메모리 사용량을 줄이기 위해 4비트 양자화 사용. 다만 양자화에 따른 손실이 있어서 필요에 따라 False로 설정 가능\n",
    "\n",
    "# 사전 학습된 모델과 토크나이저 로드\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B\",  # 사용할 모델 이름\n",
    "    max_seq_length = max_seq_length,         # 설정한 최대 시퀀스 길이\n",
    "    dtype = dtype,                           # 데이터 타입 설정\n",
    "    load_in_4bit = load_in_4bit,             # 4비트 양자화 여부\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.6.2 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# PEFT(파라미터 효율적 파인튜닝) 모델 설정\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,  # LoRA 랭크 설정. 8, 16, 32, 64, 128 권장. r 값이 클수록 모델이 더 많은 정보를 학습할 수 있지만, 너무 크면 메모리를 많이 사용\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],  # PEFT 적용할 모듈 목록. 모델의 특정 부분(모듈)에만 학습\n",
    "    lora_alpha = 16,        # LoRA 알파 설정 LoRA라는 기술이 얼마나 강하게 작용할지 조절\n",
    "    lora_dropout = 0,       # LoRA 드롭아웃 설정. 0으로 최적화\n",
    "    bias = \"none\",          # 바이어스 설정. \"none\"으로 최적화\n",
    "\n",
    "    # \"unsloth\" 사용 시 VRAM 절약 및 배치 사이즈 2배 증가\n",
    "    # 학습할 때 메모리를 절약하는 방법을 사용하는 설정\n",
    "    use_gradient_checkpointing = \"unsloth\",  # 매우 긴 컨텍스트를 위해 \"unsloth\" 설정\n",
    "    random_state = 3407,    # 랜덤 시드 설정\n",
    "    use_rslora = False,     # 랭크 안정화 LoRA 사용 여부\n",
    "    loftq_config = None,    # LoftQ 설정 (사용하지 않음)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|end_of_text|>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델에게 주어질 텍스트의 형식을 정의\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "# 맨윗줄: 모델에게 앞으로 제공될 지시사항을 기반으로 적절한 응답을 작성하라고 말함.\n",
    "# 모델이 어떤 작업을 수행해야 하는지 명확히 이해할 수 있도록 도와줌\n",
    "# Instruction:은 지시사항이 제공될 부분\n",
    "# Response:는 모델이 생성해야 할 응답이 제공될 부분\n",
    "\n",
    "# EOS 토큰 가져오기 (생성 종료를 위해 필요)\n",
    "EOS_TOKEN = tokenizer.eos_token  # 반드시 EOS_TOKEN을 추가해야 함\n",
    "EOS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 포맷팅 함수 정의\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"유저\"]  # 데이터셋의 'instruction' 필드\n",
    "    outputs      = examples[\"챗봇\"]       # 데이터셋의 'output' 필드\n",
    "    texts = []\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "                                                           # EOS_TOKEN을 추가하지 않으면 생성이 무한히 계속됨\n",
    "        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN  # 프롬프트 형식에 맞게 텍스트 생성\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }  # 'text' 필드로 반환\n",
    "\n",
    "#from datasets import load_dataset  # Hugging Face datasets 라이브러리 임포트\n",
    "\n",
    "# 데이터셋 로드 (Teddy Lee의 QA 데이터셋 미니 버전)\n",
    "#dataset = load_dataset(\"teddylee777/QA-Dataset-mini\", split = \"train\")\n",
    "\n",
    "# 프롬프트 포맷팅 함수 적용하여 데이터셋 변환\n",
    "#dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset( \"csv\", data_files = \"/home/alpaco/chat_bot/wellnis.csv\", split = \"train\")\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "# 예제 엑셀 형태로 데이터셋을 만든다면?\n",
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset( \"csv\", data_files = \"data.csv\", split = \"train\")\n",
    "# dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n다 제 잘못이에요.\\n\\n### Response:\\n낚시를 하듯이 조금 더 먼 곳을 보고, 조금 더 마음을 비우면 편안해질 거예요.<|end_of_text|>',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n어렸을 때부터 엄마보다는 아빠랑 더 친했어요.\\n\\n### Response:\\n그러시군요. 아버지에 대해 더 들려주세요.<|end_of_text|>',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n몸무게도 늘고요.\\n\\n### Response:\\n체중이 단기간에 많이 늘어나면 건강에 좋지 않다고 해요.<|end_of_text|>',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n눈물이 날 거 같더라고.\\n\\n### Response:\\n감수성이 풍부하다는 증거 같아요. 눈물이 많은 사람 중에 나쁜 사람은 없잖아요.<|end_of_text|>',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n회사를 옮기면서 직급도 올라서, 지금은 과장이에요.\\n\\n### Response:\\n그렇군요. 새로운 환경이라 적응이 필요하겠어요.<|end_of_text|>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 857 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 01:41, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.270500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.395300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.409000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.290200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.063500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.566400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.514000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.319900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.875400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.720200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.763500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.739700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.641100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.733800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.788100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.522400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.682300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.524200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.625600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.478900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.419100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.597900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.456900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.475400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.368700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.371800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.538600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.559300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.426900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.536500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.614600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.476300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.554100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.553200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.468000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.572600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.468200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.378400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.424900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.359800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.594400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.378700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.502800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.487400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.473300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.390300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.568000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.440800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.508900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.451700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 학습 설정\n",
    "from trl import SFTTrainer  # TRL 라이브러리에서 SFTTrainer 임포트\n",
    "from transformers import TrainingArguments  # 트랜스포머 라이브러리에서 TrainingArguments 임포트\n",
    "from unsloth import is_bfloat16_supported  # BFloat16 지원 여부 확인 함수 임포트\n",
    "\n",
    "# SFTTrainer 인스턴스 생성\n",
    "trainer = SFTTrainer(\n",
    "    model = model,                           # 학습할 모델\n",
    "    tokenizer = tokenizer,                   # 사용할 토크나이저\n",
    "    train_dataset = dataset,                 # 학습할 데이터셋 ★★★★★★★★\n",
    "    dataset_text_field = \"text\",             # 데이터셋의 텍스트 필드 이름 ★★★★★★★★\n",
    "    max_seq_length = max_seq_length,         # 최대 시퀀스 길이\n",
    "    dataset_num_proc = 2,                    # 데이터셋 전처리에 사용할 프로세스 수 cpu\n",
    "    packing = False,                         # 짧은 시퀀스의 경우 packing을 비활성화 (학습 속도 5배 향상 가능)\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,     # 디바이스 당 배치 사이즈\n",
    "        gradient_accumulation_steps = 4,     # 그래디언트 누적 단계 수\n",
    "        warmup_steps = 5,                     # 워밍업 스텝 수\n",
    "        # num_train_epochs = 1,               # 전체 학습 에폭 수 설정 가능\n",
    "        max_steps = 60,                       # 최대 학습 스텝 수\n",
    "        learning_rate = 2e-4,                 # 학습률\n",
    "        fp16 = not is_bfloat16_supported(),   # BFloat16 지원 여부에 따라 FP16 사용\n",
    "        bf16 = is_bfloat16_supported(),       # BFloat16 사용 여부\n",
    "        logging_steps = 1,                    # 로깅 빈도\n",
    "        optim = \"adamw_8bit\",                  # 옵티마이저 설정 (8비트 AdamW)\n",
    "        weight_decay = 0.01,                  # 가중치 감쇠\n",
    "        lr_scheduler_type = \"linear\",         # 학습률 스케줄러 타입\n",
    "        seed = 3407,                           # 랜덤 시드 설정\n",
    "        output_dir = \"outputs\",                # 출력 디렉토리\n",
    "    ),\n",
    ")\n",
    "\n",
    "## 학습 실행\n",
    "trainer_stats = trainer.train()  # 모델 학습 시작 # 3d6e4b9a0ddcd9edfafad59dcde0fd8c666954fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wellnis/tokenizer_config.json',\n",
       " 'wellnis/special_tokens_map.json',\n",
       " 'wellnis/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 저장 로컬폴더에다가 저장하는 방식\n",
    "model.save_pretrained(\"wellnis\")  # Local saving\n",
    "tokenizer.save_pretrained(\"wellnis\")\n",
    "\n",
    "# 이 이외에 허깅페이스나 다른 hub에 push해서 저장하는 방법이 있음\n",
    "# 다만, 업로드 속도와 다운로드 속도를 고려해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.2: Fast Llama patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090. Num GPUs = 1. Max memory: 23.691 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# 저장된 경로 지정\n",
    "save_directory = \"/home/alpaco/chat_bot/wellnis\"\n",
    "\n",
    "# 모델과 토크나이저 불러오기\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = save_directory,\n",
    "    max_seq_length = 2048,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True,  # 양자화 옵션을 동일하게 설정\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...기존 모델/토크나이저 로딩 코드 이후...\n",
    "\n",
    "from transformers import TextStreamer\n",
    "\n",
    "# 1. 투샷 프롬프트 정의\n",
    "two_shot_prompt = \"\"\"\n",
    "### Instruction:\n",
    "너무 무기력해.\n",
    "\n",
    "### Response:\n",
    "무기력증은 삶의 목적과 의미를 잃고, 아무 일도 하지 못하는 상태를 말합니다. 운동요법은 신체 활동을 통해 무기력증을 완화시키는 데 도움이 됩니다.\n",
    "\n",
    "### Instruction:\n",
    "무기력증 치료법을 알려줘.\n",
    "\n",
    "### Response:\n",
    "무기력증은 심리치료, 약물치료, 운동요법 등 다양한 방법으로 치료할 수 있습니다.\n",
    "\n",
    "### Instruction:\n",
    "운동이 도움이 될까?\n",
    "\n",
    "### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>\n",
      "### Instruction:\n",
      "너무 무기력해.\n",
      "\n",
      "### Response:\n",
      "무기력증은 삶의 목적과 의미를 잃고, 아무 일도 하지 못하는 상태를 말합니다. 운동요법은 신체 활동을 통해 무기력증을 완화시키는 데 도움이 됩니다.\n",
      "\n",
      "### Instruction:\n",
      "무기력증 치료법을 알려줘.\n",
      "\n",
      "### Response:\n",
      "무기력증은 심리치료, 약물치료, 운동요법 등 다양한 방법으로 치료할 수 있습니다.\n",
      "\n",
      "### Instruction:\n",
      "운동이 도움이 될까?\n",
      "\n",
      "### Response:\n",
      "운동은 신체 활동을 통해 몸과 마음을 건강하게 해줍니다.<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "# 2. 추론을 위한 입력 준비\n",
    "inputs = tokenizer(\n",
    "    two_shot_prompt,\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "# 3. TextStreamer 초기화\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "\n",
    "# 4. 모델을 사용하여 텍스트 생성 및 스트리밍 출력\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    streamer=text_streamer,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'운동은 신체 활동을 통해 몸과 마음을 건강하게 해줍니다.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. 답변만 추출\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "generated_text.split(\"### Response:\")[-1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랭체인: lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain-community: 애플리케이션을 개발할때 쓰이는 각종 기능들을 담고 있다,\n",
    "# ollama: lamma3나 다른 llm들을 다운로드 받고 쓸 수 있는 라이브러리\n",
    "# chromadb: 청킹 vector들을 저장하는 sql 종류\n",
    "# PyPDF2: pdf에서 글자를 추출해주는 라이브러리 이거 말고도 OCR로도 추출 가능(클로바ocr, 구글ocr, AI ocr모델 등)\n",
    "# !pip install --upgrade langchain langchain-community ollama chromadb PyPDF2\n",
    "# !pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4452\n",
      "iRomânăРусскийСаха тылаᱥᱟᱱᱛᱟᱲᱤScotsسنڌيSlovenčinaShqipСрпски / srpskiSvenskaతెలుగుТоҷикӣไทยУкраїнськаOʻzbekcha / ўзбекчаTiếng ViệtWinaray吴语中文粵語\n",
      "\n",
      "링크 편집\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "문서토론\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "한국어\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "읽기편집역사 보기\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "도구\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "도구\n",
      "사이드바로 이동\n",
      "숨기기\n",
      "\n",
      "\n",
      "\n",
      "\t\t동작\n",
      "\t\n",
      "\n",
      "\n",
      "읽기편집역사 보기\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t일반\n",
      "\t\n",
      "\n",
      "\n",
      "여기를 가리키는 문서가리키는 글의 최근 바뀜파일 올리기고유 링크문서 정보이 문서 인용하기축약된 URL 얻기QR코드 다운로드\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t인쇄/내보내기\n",
      "\t\n",
      "\n",
      "\n",
      "책 만들기PDF로 다운로드인쇄용 판\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t다른 프로젝트\n",
      "\t\n",
      "\n",
      "\n",
      "위키미디어 공용위키데이터 항목\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "보이기\n",
      "사이드바로 이동\n",
      "숨기기\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "위키백과, 우리 모두의 백과사전.\n",
      "\n",
      "\n",
      " 느낌은 여기로 연결됩니다. 다른 뜻에 대해서는 느낌 (동음이의) 문서를 참고하십시오.\n",
      "  법률에 대해서는 감정 (법률) 문서를, 감미료에 대해서는 사카린 문서를 참고하십시오.\n",
      "기본적인 감정의 예.\n",
      "만화적으로 표현된 일부 감정.\n",
      "감정(感情) 또는 느낌은 사람이 오감이 아닌 다른 방식으로 느끼는 것으로, 기쁨(희), 노여움(노), 슬픔(애), 즐거움(락) 등이 있다.\n",
      "\n",
      "\n",
      "역사[편집]\n",
      "감정에 대한 현대적 개념은 19세기 빌헬름 분트(Wilhelm Wundt)와 함께 발전했다.\n",
      "사회적, 심리적 정서적 선호(즉, 사람들이 좋아하는 것과 싫어하는 것)에 대한 연구에서 많은 실험이 수행되었다. 선호도, 태도, 인상 형성 및 의사 결정에 대한 구체적인 연구가 수행되었다. 이 연구는 결과를 인식 기억(기존-신판단)과 대조하여 연구자들이 둘 사이의 신뢰할 수 있는 구별을 입증할 수 있도록 한다. 정서 기반 판단과 인지 과정은 지적된 차이점으로 조사되었으며, 일부에서는 정서와 인지가 다양한 방식으로 서로 영향을 미칠 수 있는 분리\n",
      "7\n",
      "page_content='읽기편집역사 보기\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "도구\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "도구\n",
      "사이드바로 이동\n",
      "숨기기\n",
      "\n",
      "\n",
      "\n",
      "\t\t동작\n",
      "\t\n",
      "\n",
      "\n",
      "읽기편집역사 보기\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t일반\n",
      "\t\n",
      "\n",
      "\n",
      "여기를 가리키는 문서가리키는 글의 최근 바뀜파일 올리기고유 링크문서 정보이 문서 인용하기축약된 URL 얻기QR코드 다운로드\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t인쇄/내보내기\n",
      "\t\n",
      "\n",
      "\n",
      "책 만들기PDF로 다운로드인쇄용 판\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t다른 프로젝트\n",
      "\t\n",
      "\n",
      "\n",
      "위키미디어 공용위키데이터 항목\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "보이기\n",
      "사이드바로 이동\n",
      "숨기기\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "위키백과, 우리 모두의 백과사전.\n",
      "\n",
      "\n",
      " 느낌은 여기로 연결됩니다. 다른 뜻에 대해서는 느낌 (동음이의) 문서를 참고하십시오.\n",
      "  법률에 대해서는 감정 (법률) 문서를, 감미료에 대해서는 사카린 문서를 참고하십시오.\n",
      "기본적인 감정의 예.\n",
      "만화적으로 표현된 일부 감정.\n",
      "감정(感情) 또는 느낌은 사람이 오감이 아닌 다른 방식으로 느끼는 것으로, 기쁨(희), 노여움(노), 슬픔(애), 즐거움(락) 등이 있다.' metadata={'source': 'https://ko.wikipedia.org/wiki/%EA%B0%90%EC%A0%95', 'title': '감정 - 위키백과, 우리 모두의 백과사전', 'language': 'ko'}\n"
     ]
    }
   ],
   "source": [
    "# 웹 방식\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 위키피디아 감정\n",
    "url = 'https://ko.wikipedia.org/wiki/%EA%B0%90%EC%A0%95'\n",
    "loader = WebBaseLoader(url) # url을 셋팅\n",
    "\n",
    "# 웹페이지 텍스트 -> Documents\n",
    "docs = loader.load() # load 내장함수로 내용들을 불러옴\n",
    "\n",
    "# 내용출력\n",
    "print(len(docs)) # 문서의 길이\n",
    "print(len(docs[0].page_content)) # 첫번째 문서의 내용\n",
    "print(docs[0].page_content[1000:2000]) # 첫번째 문서에서 1000: 2000 구간슬라이싱\n",
    "\n",
    "\n",
    "# Text Split (Documents -> small chunks: Documents)\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 청킹 작업                           # 문장 토큰을 1000길이로 짜름(청킹한다라는뜻), overlap은 끝에 몇글자가 중복되도록 짜를거냐\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs) # 스플리터로 docs 들을 청킹함\n",
    "\n",
    "print(len(splits))\n",
    "print(splits[2])\n",
    "\n",
    "\n",
    "# PDF 파일 방식\n",
    "# uploaded = files.upload()\n",
    "# pdf_file = next(iter(uploaded))\n",
    "# print(f\"업로드된 파일: {pdf_file}\")\n",
    "\n",
    "# # PDF 텍스트 추출 및 분할\n",
    "# try:\n",
    "#     loader = PyPDFLoader(pdf_file)\n",
    "#     docs = loader.load()\n",
    "# except Exception as e:\n",
    "#     print(f\"PDF 로딩 중 오류 발생: {e}\")\n",
    "#     exit()\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'읽기편집역사 보기\\n\\n\\n\\n\\n\\n\\n\\n도구\\n\\n\\n\\n\\n\\n도구\\n사이드바로 이동\\n숨기기\\n\\n\\n\\n\\t\\t동작\\n\\t\\n\\n\\n읽기편집역사 보기\\n\\n\\n\\n\\n\\n\\t\\t일반\\n\\t\\n\\n\\n여기를 가리키는 문서가리키는 글의 최근 바뀜파일 올리기고유 링크문서 정보이 문서 인용하기축약된 URL 얻기QR코드 다운로드\\n\\n\\n\\n\\n\\n\\t\\t인쇄/내보내기\\n\\t\\n\\n\\n책 만들기PDF로 다운로드인쇄용 판\\n\\n\\n\\n\\n\\n\\t\\t다른 프로젝트\\n\\t\\n\\n\\n위키미디어 공용위키데이터 항목\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n보이기\\n사이드바로 이동\\n숨기기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n위키백과, 우리 모두의 백과사전.\\n\\n\\n 느낌은 여기로 연결됩니다. 다른 뜻에 대해서는 느낌 (동음이의) 문서를 참고하십시오.\\n  법률에 대해서는 감정 (법률) 문서를, 감미료에 대해서는 사카린 문서를 참고하십시오.\\n기본적인 감정의 예.\\n만화적으로 표현된 일부 감정.\\n감정(感情) 또는 느낌은 사람이 오감이 아닌 다른 방식으로 느끼는 것으로, 기쁨(희), 노여움(노), 슬픔(애), 즐거움(락) 등이 있다.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# page_content 속성\n",
    "splits[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://ko.wikipedia.org/wiki/%EA%B0%90%EC%A0%95',\n",
       " 'title': '감정 - 위키백과, 우리 모두의 백과사전',\n",
       " 'language': 'ko'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[2].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-openai\n",
    "#pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"API키\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing (Texts -> Embedding -> Store)\n",
    "from langchain_community.vectorstores import Chroma\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# 무료 임베딩 모델을 사용하여 임베딩 생성 (모델의 임베딩 성능에 따라 검색능력이 많이 좌우 됨.)\n",
    "# Chroma 벡터 스토어 구축\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"chroma_store_new_v2\" # 벡터스토어를 저장할 폴더이름 중복되면 안된다.\n",
    ")\n",
    "\n",
    "# 유료임베딩\n",
    "# vectorstore = Chroma.from_documents(documents=splits,\n",
    "#                                     embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "같이 보기[편집]\n",
      "감정이입\n",
      "감정 대립\n",
      "감정과 기억\n",
      "감정과 문화\n",
      "자존감\n",
      "각주[편집]\n",
      "\n",
      "\n",
      "↑ 네이버 국어사전\n",
      "\n",
      "↑ 중용\n",
      "\n",
      "↑ 청춘심리학-#4 부정적 감정의 진짜 모습에 주목하라\n",
      "\n",
      "↑ 부정적인 감정을 똑똑하게 표출하는 것은 건강에 좋다\n",
      "\n",
      "↑ 서울&-내 삶의 주인 되기 자기 이해와 자기 긍정, 행복을 위한 필수조건\n",
      "\n",
      "\n",
      "\n",
      "여성가족부-자녀연령별 육아정보-자녀의 감정을 다루어주기\n",
      "vte심리학\n",
      "역사\n",
      "심리학자\n",
      "연구 분야\n",
      "감정\n",
      "생물심리학\n",
      "임상심리학\n",
      "인지심리학\n",
      "인지 신경과학\n",
      "비교심리학\n",
      "비판심리학\n",
      "문화심리학\n",
      "발달심리학\n",
      "진화심리학\n",
      "실험심리학\n",
      "개인심리학\n",
      "해방심리학\n",
      "수리심리학\n",
      "매체심리학\n",
      "약물심리학\n",
      "신경심리학\n",
      "수행심리학\n",
      "성격심리학\n",
      "생리심리학\n",
      "정치심리학\n",
      "긍정심리학\n",
      "심리언어학\n",
      "정신병리학\n",
      "정신물리학\n",
      "심리생리학\n",
      "정성적 심리 연구\n",
      "정량적 심리 연구\n",
      "사회심리학\n",
      "이론심리학\n",
      "교육심리학\n",
      "군중심리학\n",
      "스포츠심리학\n",
      "응용 분야\n",
      "심리 실험\n",
      "임상심리학\n",
      "상담심리학\n",
      "교육심리학\n",
      "법정심리학\n",
      "건강심리학\n",
      "산업 및 조직 심리학\n",
      "법심리학\n",
      "산업 건강심리학\n",
      "관계심리학\n",
      "학교심리학\n",
      "스포츠심리학\n",
      "음향심리학\n",
      "체제심리학\n",
      "심리철학\n",
      "시각심리학\n",
      "접근 방법\n",
      "분석심리학\n",
      "행동주의\n",
      "인지주의\n",
      "인지 행동 치료\n",
      "기술심리학\n",
      "실존주의 상담\n",
      "가족 치료\n",
      "인지 정서 행동 치료\n",
      "여성주의 상담\n",
      "게슈탈트 치료\n",
      "인본주의심리학\n",
      "초심리학\n",
      "이야기 치료\n",
      "정신분석학\n",
      "정신 역동 치료\n",
      "초개인심리학\n",
      "주요 심리학자\n",
      "버러스 프레더릭 스키너\n",
      "장 피아제\n",
      "지그문트 프로이트\n",
      "오토 랑크\n",
      "멜라니 클라인\n",
      "앨버트 반두라\n",
      "레온 페스팅거\n",
      "로이 샤퍼\n",
      "칼 로저스\n",
      "스탠리 샤흐터\n",
      "닐 엘가 밀러\n",
      "에드워드 손다이크\n",
      "에이브러햄 매슬로\n",
      "고던 올포트\n",
      "에릭 에릭슨\n",
      "한스 아이젠크\n",
      "윌프레드 비용\n",
      "윌리엄 제임스\n",
      "데이비드 맥클랜드\n",
      "앨버트 엘리스\n",
      "아론 벡\n",
      "레이몬드 캐텔\n",
      "존 B. 왓슨\n",
      "쿠르트 르빈\n",
      "도널드 올딩 헤브\n",
      "조지 밀러\n",
      "클라크 헐\n",
      "제롬 케이건\n",
      "카를 융\n",
      "이반 파블로프\n",
      "앙드레 그린\n",
      "알프레트 아들러\n",
      "\n",
      "전거 통제: 국가 프랑스BnF 데이터\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "이 글은 심리학에 관한 토막글입니다. 여러분의 지식으로 알차게 문서를 완성해 갑시다.\n"
     ]
    }
   ],
   "source": [
    "docs = vectorstore.similarity_search(\"감정\")\n",
    "print(len(docs))\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo apt install curl\n",
    "# curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "# https://ollama.com/search ollama 모델들 검색후 사용할 모델 정하기\n",
    "\n",
    "# 터미널에서 실행\n",
    "# ollama serve & ollama pull gemma3:4b & ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_168029/1553611022.py:45: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(prompt=prompt, llm=llm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문을 입력하세요. 종료하려면 'exit'을 입력하세요.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_168029/1553611022.py:50: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(question)\n",
      "/tmp/ipykernel_168029/1553611022.py:57: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = llm_chain.run({\"context\": formatted_context, \"question\": question})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: This question doesn't appear to be directly answerable based on the provided text. The text is a framework for building a Wikipedia-style entry on \"Emotion.\" It lists topics, related terms, and provides a basic structure. \n",
      "\n",
      "Therefore, a response to \"안녕\" (Hello) isn’t present in the given context.\n",
      "\n",
      "답변: 제공된 문맥을 바탕으로 \"감정\"에 대한 정보를 정리하면 다음과 같습니다.\n",
      "\n",
      "**감정 - 위키백과, 우리 모두의 백과사전**\n",
      "\n",
      "*   **개요:** 감정은 인간의 정신적, 생리적 반응으로, 특정 사건이나 자극에 대한 주관적인 경험입니다.\n",
      "*   **언어:** 71개 언어로 제공됩니다.\n",
      "*   **주요 내용:**\n",
      "    *   **역사:**  (문서 내에 상세 정보는 없음)\n",
      "    *   **관련 한자어:** (문서 내에 상세 정보는 없음)\n",
      "    *   **긍정/부정 감정 표현:** (문서 내에 상세 정보는 없음)\n",
      "    *   **슬픔:** (문서 내에 상세 정보는 없음)\n",
      "    *   **정서:** (문서 내에 상세 정보는 없음)\n",
      "    *   **같이 보기:** (감정이입, 감정 대립, 감정과 기억, 감정과 문화, 자존감)\n",
      "    *   **각주:**  네이버 국어사전, 중용, 청춘심리학, 여성가족부\n",
      "\n",
      "**추가 정보:**\n",
      "\n",
      "*   문맥은 \"감정\"이라는 주제에 대한 심리학적 탐구를 위한 개요를 제공합니다.\n",
      "*   다양한 심리학적 이론(예: 감정이입, 감정 대립, 감정과 기억 등)을 다루는 것을 암시합니다.\n",
      "*   \"감정\" 관련 다양한 자료(사전, 논문, 육아 정보 등)를 참고할 수 있도록 합니다.\n",
      "\n",
      "답변: 슬픔은 감정 중에서 특히 중요하게 다루어지는 감정으로, 개인이 심리적으로 부정적인 감정들을 해소하는 카타르시스적 역할뿐만 아니라 슬픈 타인에게 연민을 줄 수 있고 자기 자신의 슬픔에 대해 타인에게서 연민을 받을 수 있는 사회적 존재로서 서로간에 균형을 갖게해주는 순기능적인 면도 있다.\n",
      "\n",
      "답변: 제공된 자료를 바탕으로 감정의 종류를 다음과 같이 정리할 수 있습니다.\n",
      "\n",
      "*   **슬픔**\n",
      "*   **정서** (감정의 일반적인 범주)\n",
      "\n",
      "또한, 자료에는 감정의 종류에 대한 직접적인 나열은 없지만, 감정 이입, 감정 대립, 감정과 기억, 감정과 문화, 자존감 등의 개념들이 관련되어 있으며, 이는 다양한 종류의 감정을 포괄하는 것으로 해석할 수 있습니다.\n",
      "\n",
      "프로그램을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# Prompt 템플릿 정의\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "# 7. Ollama Llama3 모델 설정\n",
    "# Ollama의 LLM을 LangChain과 통합하기 위해 커스텀 LLM 클래스를 정의합니다.\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Optional\n",
    "\n",
    "class OllamaLLM(LLM):\n",
    "    model_name: str = \"gemma3:4b\"\n",
    "    temperature: float = 0.0\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[list] = None) -> str:\n",
    "        response = ollama.chat(model=self.model_name, messages=[{'role': 'user', 'content': prompt}])\n",
    "        return response['message']['content']\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self):\n",
    "        return \"ollama\"\n",
    "\n",
    "# LLM 인스턴스 생성\n",
    "llm = OllamaLLM(model_name=\"gemma3:4b\", temperature=0.0) # temperature 가 작으면 모델의 대답 다양성이 적고, 높으면 대답을 다양하게 내뱉음\n",
    "\n",
    "\n",
    "# Retriever 설정\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})  # 상위 5개의 관련 문서 검색\n",
    "\n",
    "# LLMChain 설정\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "\n",
    "def rag_chain(question):\n",
    "    # 관련 문서 검색\n",
    "    retrieved_docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "    # 관련있는 문서의 내용을 뉴라인 기준으로 concatenate 함 이걸 모델한테 context로 전달해서 답변을 가져올 것이다.\n",
    "    formatted_context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "\n",
    "    # Prompt에 질문과 컨텍스트를 전달하여 답변 생성\n",
    "    answer = llm_chain.run({\"context\": formatted_context, \"question\": question})\n",
    "    return answer\n",
    "\n",
    "# 인터랙티브하게 질문하고 응답 받기\n",
    "print(\"질문을 입력하세요. 종료하려면 'exit'을 입력하세요.\")\n",
    "\n",
    "while True:\n",
    "    question = input(\"질문: \")\n",
    "    if question.lower() == 'exit':\n",
    "        print(\"프로그램을 종료합니다.\")\n",
    "        break\n",
    "    answer = rag_chain(question)\n",
    "    print(f\"답변: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 코드를 쓰고 싶다면,\n",
    "\n",
    "# 임베딩 모델 선정\n",
    "# llm 모델 선정\n",
    "# PDF 만들기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast_langch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
