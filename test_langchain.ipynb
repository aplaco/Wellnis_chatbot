{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: BNB_CUDA_VERSION=122 environment variable detected; loading libbitsandbytes_cuda122.so.\n",
      "This can be used to load a bitsandbytes version built with a CUDA version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alpaco/anaconda3/envs/fast_langch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.6.2: Fast Llama patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090. Num GPUs = 1. Max memory: 23.691 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "# Unsloth ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ FastLanguageModelì„ ì„í¬íŠ¸\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 2048 # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì„¤ì • ( í…ìŠ¤íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì§€ì •)\n",
    "dtype = None  # ìë™ ê°ì§€ë¥¼ ìœ„í•´ None ì„¤ì •. Tesla T4ëŠ” Float16, Ampere+ëŠ” Bfloat16 ì‚¬ìš©. ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì €ì¥í•  ë°ì´í„° íƒ€ì…\n",
    "load_in_4bit = True  # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ 4ë¹„íŠ¸ ì–‘ìí™” ì‚¬ìš©. ë‹¤ë§Œ ì–‘ìí™”ì— ë”°ë¥¸ ì†ì‹¤ì´ ìˆì–´ì„œ í•„ìš”ì— ë”°ë¼ Falseë¡œ ì„¤ì • ê°€ëŠ¥\n",
    "\n",
    "# ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B\",  # ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„\n",
    "    max_seq_length = max_seq_length,         # ì„¤ì •í•œ ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "    dtype = dtype,                           # ë°ì´í„° íƒ€ì… ì„¤ì •\n",
    "    load_in_4bit = load_in_4bit,             # 4ë¹„íŠ¸ ì–‘ìí™” ì—¬ë¶€\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.6.2 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# PEFT(íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  íŒŒì¸íŠœë‹) ëª¨ë¸ ì„¤ì •\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,  # LoRA ë­í¬ ì„¤ì •. 8, 16, 32, 64, 128 ê¶Œì¥. r ê°’ì´ í´ìˆ˜ë¡ ëª¨ë¸ì´ ë” ë§ì€ ì •ë³´ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆì§€ë§Œ, ë„ˆë¬´ í¬ë©´ ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],  # PEFT ì ìš©í•  ëª¨ë“ˆ ëª©ë¡. ëª¨ë¸ì˜ íŠ¹ì • ë¶€ë¶„(ëª¨ë“ˆ)ì—ë§Œ í•™ìŠµ\n",
    "    lora_alpha = 16,        # LoRA ì•ŒíŒŒ ì„¤ì • LoRAë¼ëŠ” ê¸°ìˆ ì´ ì–¼ë§ˆë‚˜ ê°•í•˜ê²Œ ì‘ìš©í• ì§€ ì¡°ì ˆ\n",
    "    lora_dropout = 0,       # LoRA ë“œë¡­ì•„ì›ƒ ì„¤ì •. 0ìœ¼ë¡œ ìµœì í™”\n",
    "    bias = \"none\",          # ë°”ì´ì–´ìŠ¤ ì„¤ì •. \"none\"ìœ¼ë¡œ ìµœì í™”\n",
    "\n",
    "    # \"unsloth\" ì‚¬ìš© ì‹œ VRAM ì ˆì•½ ë° ë°°ì¹˜ ì‚¬ì´ì¦ˆ 2ë°° ì¦ê°€\n",
    "    # í•™ìŠµí•  ë•Œ ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ëŠ” ë°©ë²•ì„ ì‚¬ìš©í•˜ëŠ” ì„¤ì •\n",
    "    use_gradient_checkpointing = \"unsloth\",  # ë§¤ìš° ê¸´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ„í•´ \"unsloth\" ì„¤ì •\n",
    "    random_state = 3407,    # ëœë¤ ì‹œë“œ ì„¤ì •\n",
    "    use_rslora = False,     # ë­í¬ ì•ˆì •í™” LoRA ì‚¬ìš© ì—¬ë¶€\n",
    "    loftq_config = None,    # LoftQ ì„¤ì • (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|end_of_text|>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ì—ê²Œ ì£¼ì–´ì§ˆ í…ìŠ¤íŠ¸ì˜ í˜•ì‹ì„ ì •ì˜\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "# ë§¨ìœ—ì¤„: ëª¨ë¸ì—ê²Œ ì•ìœ¼ë¡œ ì œê³µë  ì§€ì‹œì‚¬í•­ì„ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ì‘ë‹µì„ ì‘ì„±í•˜ë¼ê³  ë§í•¨.\n",
    "# ëª¨ë¸ì´ ì–´ë–¤ ì‘ì—…ì„ ìˆ˜í–‰í•´ì•¼ í•˜ëŠ”ì§€ ëª…í™•íˆ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤Œ\n",
    "# Instruction:ì€ ì§€ì‹œì‚¬í•­ì´ ì œê³µë  ë¶€ë¶„\n",
    "# Response:ëŠ” ëª¨ë¸ì´ ìƒì„±í•´ì•¼ í•  ì‘ë‹µì´ ì œê³µë  ë¶€ë¶„\n",
    "\n",
    "# EOS í† í° ê°€ì ¸ì˜¤ê¸° (ìƒì„± ì¢…ë£Œë¥¼ ìœ„í•´ í•„ìš”)\n",
    "EOS_TOKEN = tokenizer.eos_token  # ë°˜ë“œì‹œ EOS_TOKENì„ ì¶”ê°€í•´ì•¼ í•¨\n",
    "EOS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ… í•¨ìˆ˜ ì •ì˜\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"ìœ ì €\"]  # ë°ì´í„°ì…‹ì˜ 'instruction' í•„ë“œ\n",
    "    outputs      = examples[\"ì±—ë´‡\"]       # ë°ì´í„°ì…‹ì˜ 'output' í•„ë“œ\n",
    "    texts = []\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "                                                           # EOS_TOKENì„ ì¶”ê°€í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±ì´ ë¬´í•œíˆ ê³„ì†ë¨\n",
    "        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN  # í”„ë¡¬í”„íŠ¸ í˜•ì‹ì— ë§ê²Œ í…ìŠ¤íŠ¸ ìƒì„±\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }  # 'text' í•„ë“œë¡œ ë°˜í™˜\n",
    "\n",
    "#from datasets import load_dataset  # Hugging Face datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¡œë“œ (Teddy Leeì˜ QA ë°ì´í„°ì…‹ ë¯¸ë‹ˆ ë²„ì „)\n",
    "#dataset = load_dataset(\"teddylee777/QA-Dataset-mini\", split = \"train\")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ… í•¨ìˆ˜ ì ìš©í•˜ì—¬ ë°ì´í„°ì…‹ ë³€í™˜\n",
    "#dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset( \"csv\", data_files = \"/home/alpaco/chat_bot/wellnis.csv\", split = \"train\")\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "# ì˜ˆì œ ì—‘ì…€ í˜•íƒœë¡œ ë°ì´í„°ì…‹ì„ ë§Œë“ ë‹¤ë©´?\n",
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset( \"csv\", data_files = \"data.csv\", split = \"train\")\n",
    "# dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\në‹¤ ì œ ì˜ëª»ì´ì—ìš”.\\n\\n### Response:\\në‚šì‹œë¥¼ í•˜ë“¯ì´ ì¡°ê¸ˆ ë” ë¨¼ ê³³ì„ ë³´ê³ , ì¡°ê¸ˆ ë” ë§ˆìŒì„ ë¹„ìš°ë©´ í¸ì•ˆí•´ì§ˆ ê±°ì˜ˆìš”.<|end_of_text|>',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nì–´ë ¸ì„ ë•Œë¶€í„° ì—„ë§ˆë³´ë‹¤ëŠ” ì•„ë¹ ë‘ ë” ì¹œí–ˆì–´ìš”.\\n\\n### Response:\\nê·¸ëŸ¬ì‹œêµ°ìš”. ì•„ë²„ì§€ì— ëŒ€í•´ ë” ë“¤ë ¤ì£¼ì„¸ìš”.<|end_of_text|>',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nëª¸ë¬´ê²Œë„ ëŠ˜ê³ ìš”.\\n\\n### Response:\\nì²´ì¤‘ì´ ë‹¨ê¸°ê°„ì— ë§ì´ ëŠ˜ì–´ë‚˜ë©´ ê±´ê°•ì— ì¢‹ì§€ ì•Šë‹¤ê³  í•´ìš”.<|end_of_text|>',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nëˆˆë¬¼ì´ ë‚  ê±° ê°™ë”ë¼ê³ .\\n\\n### Response:\\nê°ìˆ˜ì„±ì´ í’ë¶€í•˜ë‹¤ëŠ” ì¦ê±° ê°™ì•„ìš”. ëˆˆë¬¼ì´ ë§ì€ ì‚¬ëŒ ì¤‘ì— ë‚˜ìœ ì‚¬ëŒì€ ì—†ì–ì•„ìš”.<|end_of_text|>',\n",
       " 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\níšŒì‚¬ë¥¼ ì˜®ê¸°ë©´ì„œ ì§ê¸‰ë„ ì˜¬ë¼ì„œ, ì§€ê¸ˆì€ ê³¼ì¥ì´ì—ìš”.\\n\\n### Response:\\nê·¸ë ‡êµ°ìš”. ìƒˆë¡œìš´ í™˜ê²½ì´ë¼ ì ì‘ì´ í•„ìš”í•˜ê² ì–´ìš”.<|end_of_text|>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 857 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 01:41, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.270500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.395300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.409000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.290200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.063500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.566400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.514000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.319900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.875400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.720200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.763500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.739700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.641100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.733800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.788100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.522400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.682300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.524200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.625600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.478900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.419100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.597900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.456900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.475400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.368700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.371800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.538600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.559300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.426900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.536500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.614600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.476300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.554100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.553200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.468000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.572600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.468200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.378400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.424900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.359800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.594400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.378700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.370200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.502800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.487400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.473300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.390300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.568000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.440800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.508900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.451700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## í•™ìŠµ ì„¤ì •\n",
    "from trl import SFTTrainer  # TRL ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ SFTTrainer ì„í¬íŠ¸\n",
    "from transformers import TrainingArguments  # íŠ¸ëœìŠ¤í¬ë¨¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ TrainingArguments ì„í¬íŠ¸\n",
    "from unsloth import is_bfloat16_supported  # BFloat16 ì§€ì› ì—¬ë¶€ í™•ì¸ í•¨ìˆ˜ ì„í¬íŠ¸\n",
    "\n",
    "# SFTTrainer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "trainer = SFTTrainer(\n",
    "    model = model,                           # í•™ìŠµí•  ëª¨ë¸\n",
    "    tokenizer = tokenizer,                   # ì‚¬ìš©í•  í† í¬ë‚˜ì´ì €\n",
    "    train_dataset = dataset,                 # í•™ìŠµí•  ë°ì´í„°ì…‹ â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…\n",
    "    dataset_text_field = \"text\",             # ë°ì´í„°ì…‹ì˜ í…ìŠ¤íŠ¸ í•„ë“œ ì´ë¦„ â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…\n",
    "    max_seq_length = max_seq_length,         # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´\n",
    "    dataset_num_proc = 2,                    # ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ì— ì‚¬ìš©í•  í”„ë¡œì„¸ìŠ¤ ìˆ˜ cpu\n",
    "    packing = False,                         # ì§§ì€ ì‹œí€€ìŠ¤ì˜ ê²½ìš° packingì„ ë¹„í™œì„±í™” (í•™ìŠµ ì†ë„ 5ë°° í–¥ìƒ ê°€ëŠ¥)\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,     # ë””ë°”ì´ìŠ¤ ë‹¹ ë°°ì¹˜ ì‚¬ì´ì¦ˆ\n",
    "        gradient_accumulation_steps = 4,     # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ë‹¨ê³„ ìˆ˜\n",
    "        warmup_steps = 5,                     # ì›Œë°ì—… ìŠ¤í… ìˆ˜\n",
    "        # num_train_epochs = 1,               # ì „ì²´ í•™ìŠµ ì—í­ ìˆ˜ ì„¤ì • ê°€ëŠ¥\n",
    "        max_steps = 60,                       # ìµœëŒ€ í•™ìŠµ ìŠ¤í… ìˆ˜\n",
    "        learning_rate = 2e-4,                 # í•™ìŠµë¥ \n",
    "        fp16 = not is_bfloat16_supported(),   # BFloat16 ì§€ì› ì—¬ë¶€ì— ë”°ë¼ FP16 ì‚¬ìš©\n",
    "        bf16 = is_bfloat16_supported(),       # BFloat16 ì‚¬ìš© ì—¬ë¶€\n",
    "        logging_steps = 1,                    # ë¡œê¹… ë¹ˆë„\n",
    "        optim = \"adamw_8bit\",                  # ì˜µí‹°ë§ˆì´ì € ì„¤ì • (8ë¹„íŠ¸ AdamW)\n",
    "        weight_decay = 0.01,                  # ê°€ì¤‘ì¹˜ ê°ì‡ \n",
    "        lr_scheduler_type = \"linear\",         # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ íƒ€ì…\n",
    "        seed = 3407,                           # ëœë¤ ì‹œë“œ ì„¤ì •\n",
    "        output_dir = \"outputs\",                # ì¶œë ¥ ë””ë ‰í† ë¦¬\n",
    "    ),\n",
    ")\n",
    "\n",
    "## í•™ìŠµ ì‹¤í–‰\n",
    "trainer_stats = trainer.train()  # ëª¨ë¸ í•™ìŠµ ì‹œì‘ # 3d6e4b9a0ddcd9edfafad59dcde0fd8c666954fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('wellnis/tokenizer_config.json',\n",
       " 'wellnis/special_tokens_map.json',\n",
       " 'wellnis/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ ì €ì¥ ë¡œì»¬í´ë”ì—ë‹¤ê°€ ì €ì¥í•˜ëŠ” ë°©ì‹\n",
    "model.save_pretrained(\"wellnis\")  # Local saving\n",
    "tokenizer.save_pretrained(\"wellnis\")\n",
    "\n",
    "# ì´ ì´ì™¸ì— í—ˆê¹…í˜ì´ìŠ¤ë‚˜ ë‹¤ë¥¸ hubì— pushí•´ì„œ ì €ì¥í•˜ëŠ” ë°©ë²•ì´ ìˆìŒ\n",
    "# ë‹¤ë§Œ, ì—…ë¡œë“œ ì†ë„ì™€ ë‹¤ìš´ë¡œë“œ ì†ë„ë¥¼ ê³ ë ¤í•´ì•¼í•¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.2: Fast Llama patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090. Num GPUs = 1. Max memory: 23.691 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# ì €ì¥ëœ ê²½ë¡œ ì§€ì •\n",
    "save_directory = \"/home/alpaco/chat_bot/wellnis\"\n",
    "\n",
    "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = save_directory,\n",
    "    max_seq_length = 2048,\n",
    "    dtype = None,\n",
    "    load_in_4bit = True,  # ì–‘ìí™” ì˜µì…˜ì„ ë™ì¼í•˜ê²Œ ì„¤ì •\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...ê¸°ì¡´ ëª¨ë¸/í† í¬ë‚˜ì´ì € ë¡œë”© ì½”ë“œ ì´í›„...\n",
    "\n",
    "from transformers import TextStreamer\n",
    "\n",
    "# 1. íˆ¬ìƒ· í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "two_shot_prompt = \"\"\"\n",
    "### Instruction:\n",
    "ë„ˆë¬´ ë¬´ê¸°ë ¥í•´.\n",
    "\n",
    "### Response:\n",
    "ë¬´ê¸°ë ¥ì¦ì€ ì‚¶ì˜ ëª©ì ê³¼ ì˜ë¯¸ë¥¼ ìƒê³ , ì•„ë¬´ ì¼ë„ í•˜ì§€ ëª»í•˜ëŠ” ìƒíƒœë¥¼ ë§í•©ë‹ˆë‹¤. ìš´ë™ìš”ë²•ì€ ì‹ ì²´ í™œë™ì„ í†µí•´ ë¬´ê¸°ë ¥ì¦ì„ ì™„í™”ì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "### Instruction:\n",
    "ë¬´ê¸°ë ¥ì¦ ì¹˜ë£Œë²•ì„ ì•Œë ¤ì¤˜.\n",
    "\n",
    "### Response:\n",
    "ë¬´ê¸°ë ¥ì¦ì€ ì‹¬ë¦¬ì¹˜ë£Œ, ì•½ë¬¼ì¹˜ë£Œ, ìš´ë™ìš”ë²• ë“± ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ì¹˜ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### Instruction:\n",
    "ìš´ë™ì´ ë„ì›€ì´ ë ê¹Œ?\n",
    "\n",
    "### Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>\n",
      "### Instruction:\n",
      "ë„ˆë¬´ ë¬´ê¸°ë ¥í•´.\n",
      "\n",
      "### Response:\n",
      "ë¬´ê¸°ë ¥ì¦ì€ ì‚¶ì˜ ëª©ì ê³¼ ì˜ë¯¸ë¥¼ ìƒê³ , ì•„ë¬´ ì¼ë„ í•˜ì§€ ëª»í•˜ëŠ” ìƒíƒœë¥¼ ë§í•©ë‹ˆë‹¤. ìš´ë™ìš”ë²•ì€ ì‹ ì²´ í™œë™ì„ í†µí•´ ë¬´ê¸°ë ¥ì¦ì„ ì™„í™”ì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "### Instruction:\n",
      "ë¬´ê¸°ë ¥ì¦ ì¹˜ë£Œë²•ì„ ì•Œë ¤ì¤˜.\n",
      "\n",
      "### Response:\n",
      "ë¬´ê¸°ë ¥ì¦ì€ ì‹¬ë¦¬ì¹˜ë£Œ, ì•½ë¬¼ì¹˜ë£Œ, ìš´ë™ìš”ë²• ë“± ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ì¹˜ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### Instruction:\n",
      "ìš´ë™ì´ ë„ì›€ì´ ë ê¹Œ?\n",
      "\n",
      "### Response:\n",
      "ìš´ë™ì€ ì‹ ì²´ í™œë™ì„ í†µí•´ ëª¸ê³¼ ë§ˆìŒì„ ê±´ê°•í•˜ê²Œ í•´ì¤ë‹ˆë‹¤.<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "# 2. ì¶”ë¡ ì„ ìœ„í•œ ì…ë ¥ ì¤€ë¹„\n",
    "inputs = tokenizer(\n",
    "    two_shot_prompt,\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "# 3. TextStreamer ì´ˆê¸°í™”\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "\n",
    "# 4. ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„± ë° ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    streamer=text_streamer,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìš´ë™ì€ ì‹ ì²´ í™œë™ì„ í†µí•´ ëª¸ê³¼ ë§ˆìŒì„ ê±´ê°•í•˜ê²Œ í•´ì¤ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. ë‹µë³€ë§Œ ì¶”ì¶œ\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "generated_text.split(\"### Response:\")[-1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë­ì²´ì¸: lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain-community: ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí• ë•Œ ì“°ì´ëŠ” ê°ì¢… ê¸°ëŠ¥ë“¤ì„ ë‹´ê³  ìˆë‹¤,\n",
    "# ollama: lamma3ë‚˜ ë‹¤ë¥¸ llmë“¤ì„ ë‹¤ìš´ë¡œë“œ ë°›ê³  ì“¸ ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# chromadb: ì²­í‚¹ vectorë“¤ì„ ì €ì¥í•˜ëŠ” sql ì¢…ë¥˜\n",
    "# PyPDF2: pdfì—ì„œ ê¸€ìë¥¼ ì¶”ì¶œí•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì´ê±° ë§ê³ ë„ OCRë¡œë„ ì¶”ì¶œ ê°€ëŠ¥(í´ë¡œë°”ocr, êµ¬ê¸€ocr, AI ocrëª¨ë¸ ë“±)\n",
    "# !pip install --upgrade langchain langchain-community ollama chromadb PyPDF2\n",
    "# !pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4452\n",
      "iRomÃ¢nÄƒĞ ÑƒÑÑĞºĞ¸Ğ¹Ğ¡Ğ°Ñ…Ğ° Ñ‚Ñ‹Ğ»Ğ°á±¥á±Ÿá±±á±›á±Ÿá±²á±¤ScotsØ³Ù†ÚŒÙŠSlovenÄinaShqipĞ¡Ñ€Ğ¿ÑĞºĞ¸ / srpskiSvenskaà°¤à±†à°²à±à°—à±Ğ¢Ğ¾Ò·Ğ¸ĞºÓ£à¹„à¸—à¸¢Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°OÊ»zbekcha / ÑĞ·Ğ±ĞµĞºÑ‡Ğ°Tiáº¿ng Viá»‡tWinarayå´è¯­ä¸­æ–‡ç²µèª\n",
      "\n",
      "ë§í¬ í¸ì§‘\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ë¬¸ì„œí† ë¡ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "í•œêµ­ì–´\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ì½ê¸°í¸ì§‘ì—­ì‚¬ ë³´ê¸°\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ë„êµ¬\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ë„êµ¬\n",
      "ì‚¬ì´ë“œë°”ë¡œ ì´ë™\n",
      "ìˆ¨ê¸°ê¸°\n",
      "\n",
      "\n",
      "\n",
      "\t\të™ì‘\n",
      "\t\n",
      "\n",
      "\n",
      "ì½ê¸°í¸ì§‘ì—­ì‚¬ ë³´ê¸°\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tì¼ë°˜\n",
      "\t\n",
      "\n",
      "\n",
      "ì—¬ê¸°ë¥¼ ê°€ë¦¬í‚¤ëŠ” ë¬¸ì„œê°€ë¦¬í‚¤ëŠ” ê¸€ì˜ ìµœê·¼ ë°”ë€œíŒŒì¼ ì˜¬ë¦¬ê¸°ê³ ìœ  ë§í¬ë¬¸ì„œ ì •ë³´ì´ ë¬¸ì„œ ì¸ìš©í•˜ê¸°ì¶•ì•½ëœ URL ì–»ê¸°QRì½”ë“œ ë‹¤ìš´ë¡œë“œ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tì¸ì‡„/ë‚´ë³´ë‚´ê¸°\n",
      "\t\n",
      "\n",
      "\n",
      "ì±… ë§Œë“¤ê¸°PDFë¡œ ë‹¤ìš´ë¡œë“œì¸ì‡„ìš© íŒ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\të‹¤ë¥¸ í”„ë¡œì íŠ¸\n",
      "\t\n",
      "\n",
      "\n",
      "ìœ„í‚¤ë¯¸ë””ì–´ ê³µìš©ìœ„í‚¤ë°ì´í„° í•­ëª©\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ë³´ì´ê¸°\n",
      "ì‚¬ì´ë“œë°”ë¡œ ì´ë™\n",
      "ìˆ¨ê¸°ê¸°\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ìœ„í‚¤ë°±ê³¼, ìš°ë¦¬ ëª¨ë‘ì˜ ë°±ê³¼ì‚¬ì „.\n",
      "\n",
      "\n",
      " ëŠë‚Œì€ ì—¬ê¸°ë¡œ ì—°ê²°ë©ë‹ˆë‹¤. ë‹¤ë¥¸ ëœ»ì— ëŒ€í•´ì„œëŠ” ëŠë‚Œ (ë™ìŒì´ì˜) ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì‹­ì‹œì˜¤.\n",
      "  ë²•ë¥ ì— ëŒ€í•´ì„œëŠ” ê°ì • (ë²•ë¥ ) ë¬¸ì„œë¥¼, ê°ë¯¸ë£Œì— ëŒ€í•´ì„œëŠ” ì‚¬ì¹´ë¦° ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì‹­ì‹œì˜¤.\n",
      "ê¸°ë³¸ì ì¸ ê°ì •ì˜ ì˜ˆ.\n",
      "ë§Œí™”ì ìœ¼ë¡œ í‘œí˜„ëœ ì¼ë¶€ ê°ì •.\n",
      "ê°ì •(æ„Ÿæƒ…) ë˜ëŠ” ëŠë‚Œì€ ì‚¬ëŒì´ ì˜¤ê°ì´ ì•„ë‹Œ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ëŠë¼ëŠ” ê²ƒìœ¼ë¡œ, ê¸°ì¨(í¬), ë…¸ì—¬ì›€(ë…¸), ìŠ¬í””(ì• ), ì¦ê±°ì›€(ë½) ë“±ì´ ìˆë‹¤.\n",
      "\n",
      "\n",
      "ì—­ì‚¬[í¸ì§‘]\n",
      "ê°ì •ì— ëŒ€í•œ í˜„ëŒ€ì  ê°œë…ì€ 19ì„¸ê¸° ë¹Œí—¬ë¦„ ë¶„íŠ¸(Wilhelm Wundt)ì™€ í•¨ê»˜ ë°œì „í–ˆë‹¤.\n",
      "ì‚¬íšŒì , ì‹¬ë¦¬ì  ì •ì„œì  ì„ í˜¸(ì¦‰, ì‚¬ëŒë“¤ì´ ì¢‹ì•„í•˜ëŠ” ê²ƒê³¼ ì‹«ì–´í•˜ëŠ” ê²ƒ)ì— ëŒ€í•œ ì—°êµ¬ì—ì„œ ë§ì€ ì‹¤í—˜ì´ ìˆ˜í–‰ë˜ì—ˆë‹¤. ì„ í˜¸ë„, íƒœë„, ì¸ìƒ í˜•ì„± ë° ì˜ì‚¬ ê²°ì •ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì—°êµ¬ê°€ ìˆ˜í–‰ë˜ì—ˆë‹¤. ì´ ì—°êµ¬ëŠ” ê²°ê³¼ë¥¼ ì¸ì‹ ê¸°ì–µ(ê¸°ì¡´-ì‹ íŒë‹¨)ê³¼ ëŒ€ì¡°í•˜ì—¬ ì—°êµ¬ìë“¤ì´ ë‘˜ ì‚¬ì´ì˜ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” êµ¬ë³„ì„ ì…ì¦í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤. ì •ì„œ ê¸°ë°˜ íŒë‹¨ê³¼ ì¸ì§€ ê³¼ì •ì€ ì§€ì ëœ ì°¨ì´ì ìœ¼ë¡œ ì¡°ì‚¬ë˜ì—ˆìœ¼ë©°, ì¼ë¶€ì—ì„œëŠ” ì •ì„œì™€ ì¸ì§€ê°€ ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ì„œë¡œ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” ë¶„ë¦¬\n",
      "7\n",
      "page_content='ì½ê¸°í¸ì§‘ì—­ì‚¬ ë³´ê¸°\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ë„êµ¬\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ë„êµ¬\n",
      "ì‚¬ì´ë“œë°”ë¡œ ì´ë™\n",
      "ìˆ¨ê¸°ê¸°\n",
      "\n",
      "\n",
      "\n",
      "\t\të™ì‘\n",
      "\t\n",
      "\n",
      "\n",
      "ì½ê¸°í¸ì§‘ì—­ì‚¬ ë³´ê¸°\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tì¼ë°˜\n",
      "\t\n",
      "\n",
      "\n",
      "ì—¬ê¸°ë¥¼ ê°€ë¦¬í‚¤ëŠ” ë¬¸ì„œê°€ë¦¬í‚¤ëŠ” ê¸€ì˜ ìµœê·¼ ë°”ë€œíŒŒì¼ ì˜¬ë¦¬ê¸°ê³ ìœ  ë§í¬ë¬¸ì„œ ì •ë³´ì´ ë¬¸ì„œ ì¸ìš©í•˜ê¸°ì¶•ì•½ëœ URL ì–»ê¸°QRì½”ë“œ ë‹¤ìš´ë¡œë“œ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tì¸ì‡„/ë‚´ë³´ë‚´ê¸°\n",
      "\t\n",
      "\n",
      "\n",
      "ì±… ë§Œë“¤ê¸°PDFë¡œ ë‹¤ìš´ë¡œë“œì¸ì‡„ìš© íŒ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\të‹¤ë¥¸ í”„ë¡œì íŠ¸\n",
      "\t\n",
      "\n",
      "\n",
      "ìœ„í‚¤ë¯¸ë””ì–´ ê³µìš©ìœ„í‚¤ë°ì´í„° í•­ëª©\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ë³´ì´ê¸°\n",
      "ì‚¬ì´ë“œë°”ë¡œ ì´ë™\n",
      "ìˆ¨ê¸°ê¸°\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ìœ„í‚¤ë°±ê³¼, ìš°ë¦¬ ëª¨ë‘ì˜ ë°±ê³¼ì‚¬ì „.\n",
      "\n",
      "\n",
      " ëŠë‚Œì€ ì—¬ê¸°ë¡œ ì—°ê²°ë©ë‹ˆë‹¤. ë‹¤ë¥¸ ëœ»ì— ëŒ€í•´ì„œëŠ” ëŠë‚Œ (ë™ìŒì´ì˜) ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì‹­ì‹œì˜¤.\n",
      "  ë²•ë¥ ì— ëŒ€í•´ì„œëŠ” ê°ì • (ë²•ë¥ ) ë¬¸ì„œë¥¼, ê°ë¯¸ë£Œì— ëŒ€í•´ì„œëŠ” ì‚¬ì¹´ë¦° ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì‹­ì‹œì˜¤.\n",
      "ê¸°ë³¸ì ì¸ ê°ì •ì˜ ì˜ˆ.\n",
      "ë§Œí™”ì ìœ¼ë¡œ í‘œí˜„ëœ ì¼ë¶€ ê°ì •.\n",
      "ê°ì •(æ„Ÿæƒ…) ë˜ëŠ” ëŠë‚Œì€ ì‚¬ëŒì´ ì˜¤ê°ì´ ì•„ë‹Œ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ëŠë¼ëŠ” ê²ƒìœ¼ë¡œ, ê¸°ì¨(í¬), ë…¸ì—¬ì›€(ë…¸), ìŠ¬í””(ì• ), ì¦ê±°ì›€(ë½) ë“±ì´ ìˆë‹¤.' metadata={'source': 'https://ko.wikipedia.org/wiki/%EA%B0%90%EC%A0%95', 'title': 'ê°ì • - ìœ„í‚¤ë°±ê³¼, ìš°ë¦¬ ëª¨ë‘ì˜ ë°±ê³¼ì‚¬ì „', 'language': 'ko'}\n"
     ]
    }
   ],
   "source": [
    "# ì›¹ ë°©ì‹\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# ìœ„í‚¤í”¼ë””ì•„ ê°ì •\n",
    "url = 'https://ko.wikipedia.org/wiki/%EA%B0%90%EC%A0%95'\n",
    "loader = WebBaseLoader(url) # urlì„ ì…‹íŒ…\n",
    "\n",
    "# ì›¹í˜ì´ì§€ í…ìŠ¤íŠ¸ -> Documents\n",
    "docs = loader.load() # load ë‚´ì¥í•¨ìˆ˜ë¡œ ë‚´ìš©ë“¤ì„ ë¶ˆëŸ¬ì˜´\n",
    "\n",
    "# ë‚´ìš©ì¶œë ¥\n",
    "print(len(docs)) # ë¬¸ì„œì˜ ê¸¸ì´\n",
    "print(len(docs[0].page_content)) # ì²«ë²ˆì§¸ ë¬¸ì„œì˜ ë‚´ìš©\n",
    "print(docs[0].page_content[1000:2000]) # ì²«ë²ˆì§¸ ë¬¸ì„œì—ì„œ 1000: 2000 êµ¬ê°„ìŠ¬ë¼ì´ì‹±\n",
    "\n",
    "\n",
    "# Text Split (Documents -> small chunks: Documents)\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# ì²­í‚¹ ì‘ì—…                           # ë¬¸ì¥ í† í°ì„ 1000ê¸¸ì´ë¡œ ì§œë¦„(ì²­í‚¹í•œë‹¤ë¼ëŠ”ëœ»), overlapì€ ëì— ëª‡ê¸€ìê°€ ì¤‘ë³µë˜ë„ë¡ ì§œë¥¼ê±°ëƒ\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs) # ìŠ¤í”Œë¦¬í„°ë¡œ docs ë“¤ì„ ì²­í‚¹í•¨\n",
    "\n",
    "print(len(splits))\n",
    "print(splits[2])\n",
    "\n",
    "\n",
    "# PDF íŒŒì¼ ë°©ì‹\n",
    "# uploaded = files.upload()\n",
    "# pdf_file = next(iter(uploaded))\n",
    "# print(f\"ì—…ë¡œë“œëœ íŒŒì¼: {pdf_file}\")\n",
    "\n",
    "# # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë¶„í• \n",
    "# try:\n",
    "#     loader = PyPDFLoader(pdf_file)\n",
    "#     docs = loader.load()\n",
    "# except Exception as e:\n",
    "#     print(f\"PDF ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "#     exit()\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì½ê¸°í¸ì§‘ì—­ì‚¬ ë³´ê¸°\\n\\n\\n\\n\\n\\n\\n\\në„êµ¬\\n\\n\\n\\n\\n\\në„êµ¬\\nì‚¬ì´ë“œë°”ë¡œ ì´ë™\\nìˆ¨ê¸°ê¸°\\n\\n\\n\\n\\t\\të™ì‘\\n\\t\\n\\n\\nì½ê¸°í¸ì§‘ì—­ì‚¬ ë³´ê¸°\\n\\n\\n\\n\\n\\n\\t\\tì¼ë°˜\\n\\t\\n\\n\\nì—¬ê¸°ë¥¼ ê°€ë¦¬í‚¤ëŠ” ë¬¸ì„œê°€ë¦¬í‚¤ëŠ” ê¸€ì˜ ìµœê·¼ ë°”ë€œíŒŒì¼ ì˜¬ë¦¬ê¸°ê³ ìœ  ë§í¬ë¬¸ì„œ ì •ë³´ì´ ë¬¸ì„œ ì¸ìš©í•˜ê¸°ì¶•ì•½ëœ URL ì–»ê¸°QRì½”ë“œ ë‹¤ìš´ë¡œë“œ\\n\\n\\n\\n\\n\\n\\t\\tì¸ì‡„/ë‚´ë³´ë‚´ê¸°\\n\\t\\n\\n\\nì±… ë§Œë“¤ê¸°PDFë¡œ ë‹¤ìš´ë¡œë“œì¸ì‡„ìš© íŒ\\n\\n\\n\\n\\n\\n\\t\\të‹¤ë¥¸ í”„ë¡œì íŠ¸\\n\\t\\n\\n\\nìœ„í‚¤ë¯¸ë””ì–´ ê³µìš©ìœ„í‚¤ë°ì´í„° í•­ëª©\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\në³´ì´ê¸°\\nì‚¬ì´ë“œë°”ë¡œ ì´ë™\\nìˆ¨ê¸°ê¸°\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nìœ„í‚¤ë°±ê³¼, ìš°ë¦¬ ëª¨ë‘ì˜ ë°±ê³¼ì‚¬ì „.\\n\\n\\n ëŠë‚Œì€ ì—¬ê¸°ë¡œ ì—°ê²°ë©ë‹ˆë‹¤. ë‹¤ë¥¸ ëœ»ì— ëŒ€í•´ì„œëŠ” ëŠë‚Œ (ë™ìŒì´ì˜) ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì‹­ì‹œì˜¤.\\n  ë²•ë¥ ì— ëŒ€í•´ì„œëŠ” ê°ì • (ë²•ë¥ ) ë¬¸ì„œë¥¼, ê°ë¯¸ë£Œì— ëŒ€í•´ì„œëŠ” ì‚¬ì¹´ë¦° ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì‹­ì‹œì˜¤.\\nê¸°ë³¸ì ì¸ ê°ì •ì˜ ì˜ˆ.\\në§Œí™”ì ìœ¼ë¡œ í‘œí˜„ëœ ì¼ë¶€ ê°ì •.\\nê°ì •(æ„Ÿæƒ…) ë˜ëŠ” ëŠë‚Œì€ ì‚¬ëŒì´ ì˜¤ê°ì´ ì•„ë‹Œ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ëŠë¼ëŠ” ê²ƒìœ¼ë¡œ, ê¸°ì¨(í¬), ë…¸ì—¬ì›€(ë…¸), ìŠ¬í””(ì• ), ì¦ê±°ì›€(ë½) ë“±ì´ ìˆë‹¤.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# page_content ì†ì„±\n",
    "splits[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://ko.wikipedia.org/wiki/%EA%B0%90%EC%A0%95',\n",
       " 'title': 'ê°ì • - ìœ„í‚¤ë°±ê³¼, ìš°ë¦¬ ëª¨ë‘ì˜ ë°±ê³¼ì‚¬ì „',\n",
       " 'language': 'ko'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[2].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-openai\n",
    "#pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"APIí‚¤\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing (Texts -> Embedding -> Store)\n",
    "from langchain_community.vectorstores import Chroma\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# ë¬´ë£Œ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ìƒì„± (ëª¨ë¸ì˜ ì„ë² ë”© ì„±ëŠ¥ì— ë”°ë¼ ê²€ìƒ‰ëŠ¥ë ¥ì´ ë§ì´ ì¢Œìš° ë¨.)\n",
    "# Chroma ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-mpnet-base-v2\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"chroma_store_new_v2\" # ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì €ì¥í•  í´ë”ì´ë¦„ ì¤‘ë³µë˜ë©´ ì•ˆëœë‹¤.\n",
    ")\n",
    "\n",
    "# ìœ ë£Œì„ë² ë”©\n",
    "# vectorstore = Chroma.from_documents(documents=splits,\n",
    "#                                     embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "ê°™ì´ ë³´ê¸°[í¸ì§‘]\n",
      "ê°ì •ì´ì…\n",
      "ê°ì • ëŒ€ë¦½\n",
      "ê°ì •ê³¼ ê¸°ì–µ\n",
      "ê°ì •ê³¼ ë¬¸í™”\n",
      "ìì¡´ê°\n",
      "ê°ì£¼[í¸ì§‘]\n",
      "\n",
      "\n",
      "â†‘ ë„¤ì´ë²„ êµ­ì–´ì‚¬ì „\n",
      "\n",
      "â†‘ ì¤‘ìš©\n",
      "\n",
      "â†‘ ì²­ì¶˜ì‹¬ë¦¬í•™-#4 ë¶€ì •ì  ê°ì •ì˜ ì§„ì§œ ëª¨ìŠµì— ì£¼ëª©í•˜ë¼\n",
      "\n",
      "â†‘ ë¶€ì •ì ì¸ ê°ì •ì„ ë˜‘ë˜‘í•˜ê²Œ í‘œì¶œí•˜ëŠ” ê²ƒì€ ê±´ê°•ì— ì¢‹ë‹¤\n",
      "\n",
      "â†‘ ì„œìš¸&-ë‚´ ì‚¶ì˜ ì£¼ì¸ ë˜ê¸° ìê¸° ì´í•´ì™€ ìê¸° ê¸ì •, í–‰ë³µì„ ìœ„í•œ í•„ìˆ˜ì¡°ê±´\n",
      "\n",
      "\n",
      "\n",
      "ì—¬ì„±ê°€ì¡±ë¶€-ìë…€ì—°ë ¹ë³„ ìœ¡ì•„ì •ë³´-ìë…€ì˜ ê°ì •ì„ ë‹¤ë£¨ì–´ì£¼ê¸°\n",
      "vteì‹¬ë¦¬í•™\n",
      "ì—­ì‚¬\n",
      "ì‹¬ë¦¬í•™ì\n",
      "ì—°êµ¬ ë¶„ì•¼\n",
      "ê°ì •\n",
      "ìƒë¬¼ì‹¬ë¦¬í•™\n",
      "ì„ìƒì‹¬ë¦¬í•™\n",
      "ì¸ì§€ì‹¬ë¦¬í•™\n",
      "ì¸ì§€ ì‹ ê²½ê³¼í•™\n",
      "ë¹„êµì‹¬ë¦¬í•™\n",
      "ë¹„íŒì‹¬ë¦¬í•™\n",
      "ë¬¸í™”ì‹¬ë¦¬í•™\n",
      "ë°œë‹¬ì‹¬ë¦¬í•™\n",
      "ì§„í™”ì‹¬ë¦¬í•™\n",
      "ì‹¤í—˜ì‹¬ë¦¬í•™\n",
      "ê°œì¸ì‹¬ë¦¬í•™\n",
      "í•´ë°©ì‹¬ë¦¬í•™\n",
      "ìˆ˜ë¦¬ì‹¬ë¦¬í•™\n",
      "ë§¤ì²´ì‹¬ë¦¬í•™\n",
      "ì•½ë¬¼ì‹¬ë¦¬í•™\n",
      "ì‹ ê²½ì‹¬ë¦¬í•™\n",
      "ìˆ˜í–‰ì‹¬ë¦¬í•™\n",
      "ì„±ê²©ì‹¬ë¦¬í•™\n",
      "ìƒë¦¬ì‹¬ë¦¬í•™\n",
      "ì •ì¹˜ì‹¬ë¦¬í•™\n",
      "ê¸ì •ì‹¬ë¦¬í•™\n",
      "ì‹¬ë¦¬ì–¸ì–´í•™\n",
      "ì •ì‹ ë³‘ë¦¬í•™\n",
      "ì •ì‹ ë¬¼ë¦¬í•™\n",
      "ì‹¬ë¦¬ìƒë¦¬í•™\n",
      "ì •ì„±ì  ì‹¬ë¦¬ ì—°êµ¬\n",
      "ì •ëŸ‰ì  ì‹¬ë¦¬ ì—°êµ¬\n",
      "ì‚¬íšŒì‹¬ë¦¬í•™\n",
      "ì´ë¡ ì‹¬ë¦¬í•™\n",
      "êµìœ¡ì‹¬ë¦¬í•™\n",
      "êµ°ì¤‘ì‹¬ë¦¬í•™\n",
      "ìŠ¤í¬ì¸ ì‹¬ë¦¬í•™\n",
      "ì‘ìš© ë¶„ì•¼\n",
      "ì‹¬ë¦¬ ì‹¤í—˜\n",
      "ì„ìƒì‹¬ë¦¬í•™\n",
      "ìƒë‹´ì‹¬ë¦¬í•™\n",
      "êµìœ¡ì‹¬ë¦¬í•™\n",
      "ë²•ì •ì‹¬ë¦¬í•™\n",
      "ê±´ê°•ì‹¬ë¦¬í•™\n",
      "ì‚°ì—… ë° ì¡°ì§ ì‹¬ë¦¬í•™\n",
      "ë²•ì‹¬ë¦¬í•™\n",
      "ì‚°ì—… ê±´ê°•ì‹¬ë¦¬í•™\n",
      "ê´€ê³„ì‹¬ë¦¬í•™\n",
      "í•™êµì‹¬ë¦¬í•™\n",
      "ìŠ¤í¬ì¸ ì‹¬ë¦¬í•™\n",
      "ìŒí–¥ì‹¬ë¦¬í•™\n",
      "ì²´ì œì‹¬ë¦¬í•™\n",
      "ì‹¬ë¦¬ì² í•™\n",
      "ì‹œê°ì‹¬ë¦¬í•™\n",
      "ì ‘ê·¼ ë°©ë²•\n",
      "ë¶„ì„ì‹¬ë¦¬í•™\n",
      "í–‰ë™ì£¼ì˜\n",
      "ì¸ì§€ì£¼ì˜\n",
      "ì¸ì§€ í–‰ë™ ì¹˜ë£Œ\n",
      "ê¸°ìˆ ì‹¬ë¦¬í•™\n",
      "ì‹¤ì¡´ì£¼ì˜ ìƒë‹´\n",
      "ê°€ì¡± ì¹˜ë£Œ\n",
      "ì¸ì§€ ì •ì„œ í–‰ë™ ì¹˜ë£Œ\n",
      "ì—¬ì„±ì£¼ì˜ ìƒë‹´\n",
      "ê²ŒìŠˆíƒˆíŠ¸ ì¹˜ë£Œ\n",
      "ì¸ë³¸ì£¼ì˜ì‹¬ë¦¬í•™\n",
      "ì´ˆì‹¬ë¦¬í•™\n",
      "ì´ì•¼ê¸° ì¹˜ë£Œ\n",
      "ì •ì‹ ë¶„ì„í•™\n",
      "ì •ì‹  ì—­ë™ ì¹˜ë£Œ\n",
      "ì´ˆê°œì¸ì‹¬ë¦¬í•™\n",
      "ì£¼ìš” ì‹¬ë¦¬í•™ì\n",
      "ë²„ëŸ¬ìŠ¤ í”„ë ˆë”ë¦­ ìŠ¤í‚¤ë„ˆ\n",
      "ì¥ í”¼ì•„ì œ\n",
      "ì§€ê·¸ë¬¸íŠ¸ í”„ë¡œì´íŠ¸\n",
      "ì˜¤í†  ë‘í¬\n",
      "ë©œë¼ë‹ˆ í´ë¼ì¸\n",
      "ì•¨ë²„íŠ¸ ë°˜ë‘ë¼\n",
      "ë ˆì˜¨ í˜ìŠ¤íŒ…ê±°\n",
      "ë¡œì´ ìƒ¤í¼\n",
      "ì¹¼ ë¡œì €ìŠ¤\n",
      "ìŠ¤íƒ ë¦¬ ìƒ¤íí„°\n",
      "ë‹ ì—˜ê°€ ë°€ëŸ¬\n",
      "ì—ë“œì›Œë“œ ì†ë‹¤ì´í¬\n",
      "ì—ì´ë¸ŒëŸ¬í–„ ë§¤ìŠ¬ë¡œ\n",
      "ê³ ë˜ ì˜¬í¬íŠ¸\n",
      "ì—ë¦­ ì—ë¦­ìŠ¨\n",
      "í•œìŠ¤ ì•„ì´ì  í¬\n",
      "ìœŒí”„ë ˆë“œ ë¹„ìš©\n",
      "ìœŒë¦¬ì—„ ì œì„ìŠ¤\n",
      "ë°ì´ë¹„ë“œ ë§¥í´ëœë“œ\n",
      "ì•¨ë²„íŠ¸ ì—˜ë¦¬ìŠ¤\n",
      "ì•„ë¡  ë²¡\n",
      "ë ˆì´ëª¬ë“œ ìºí…”\n",
      "ì¡´ B. ì™“ìŠ¨\n",
      "ì¿ ë¥´íŠ¸ ë¥´ë¹ˆ\n",
      "ë„ë„ë“œ ì˜¬ë”© í—¤ë¸Œ\n",
      "ì¡°ì§€ ë°€ëŸ¬\n",
      "í´ë¼í¬ í—\n",
      "ì œë¡¬ ì¼€ì´ê±´\n",
      "ì¹´ë¥¼ ìœµ\n",
      "ì´ë°˜ íŒŒë¸”ë¡œí”„\n",
      "ì•™ë“œë ˆ ê·¸ë¦°\n",
      "ì•Œí”„ë ˆíŠ¸ ì•„ë“¤ëŸ¬\n",
      "\n",
      "ì „ê±° í†µì œ: êµ­ê°€ í”„ë‘ìŠ¤BnF ë°ì´í„°\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ì´ ê¸€ì€ ì‹¬ë¦¬í•™ì— ê´€í•œ í† ë§‰ê¸€ì…ë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ì˜ ì§€ì‹ìœ¼ë¡œ ì•Œì°¨ê²Œ ë¬¸ì„œë¥¼ ì™„ì„±í•´ ê°‘ì‹œë‹¤.\n"
     ]
    }
   ],
   "source": [
    "docs = vectorstore.similarity_search(\"ê°ì •\")\n",
    "print(len(docs))\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo apt install curl\n",
    "# curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "# https://ollama.com/search ollama ëª¨ë¸ë“¤ ê²€ìƒ‰í›„ ì‚¬ìš©í•  ëª¨ë¸ ì •í•˜ê¸°\n",
    "\n",
    "# í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰\n",
    "# ollama serve & ollama pull gemma3:4b & ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_168029/1553611022.py:45: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(prompt=prompt, llm=llm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. ì¢…ë£Œí•˜ë ¤ë©´ 'exit'ì„ ì…ë ¥í•˜ì„¸ìš”.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_168029/1553611022.py:50: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(question)\n",
      "/tmp/ipykernel_168029/1553611022.py:57: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = llm_chain.run({\"context\": formatted_context, \"question\": question})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹µë³€: This question doesn't appear to be directly answerable based on the provided text. The text is a framework for building a Wikipedia-style entry on \"Emotion.\" It lists topics, related terms, and provides a basic structure. \n",
      "\n",
      "Therefore, a response to \"ì•ˆë…•\" (Hello) isnâ€™t present in the given context.\n",
      "\n",
      "ë‹µë³€: ì œê³µëœ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ \"ê°ì •\"ì— ëŒ€í•œ ì •ë³´ë¥¼ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ê°ì • - ìœ„í‚¤ë°±ê³¼, ìš°ë¦¬ ëª¨ë‘ì˜ ë°±ê³¼ì‚¬ì „**\n",
      "\n",
      "*   **ê°œìš”:** ê°ì •ì€ ì¸ê°„ì˜ ì •ì‹ ì , ìƒë¦¬ì  ë°˜ì‘ìœ¼ë¡œ, íŠ¹ì • ì‚¬ê±´ì´ë‚˜ ìê·¹ì— ëŒ€í•œ ì£¼ê´€ì ì¸ ê²½í—˜ì…ë‹ˆë‹¤.\n",
      "*   **ì–¸ì–´:** 71ê°œ ì–¸ì–´ë¡œ ì œê³µë©ë‹ˆë‹¤.\n",
      "*   **ì£¼ìš” ë‚´ìš©:**\n",
      "    *   **ì—­ì‚¬:**  (ë¬¸ì„œ ë‚´ì— ìƒì„¸ ì •ë³´ëŠ” ì—†ìŒ)\n",
      "    *   **ê´€ë ¨ í•œìì–´:** (ë¬¸ì„œ ë‚´ì— ìƒì„¸ ì •ë³´ëŠ” ì—†ìŒ)\n",
      "    *   **ê¸ì •/ë¶€ì • ê°ì • í‘œí˜„:** (ë¬¸ì„œ ë‚´ì— ìƒì„¸ ì •ë³´ëŠ” ì—†ìŒ)\n",
      "    *   **ìŠ¬í””:** (ë¬¸ì„œ ë‚´ì— ìƒì„¸ ì •ë³´ëŠ” ì—†ìŒ)\n",
      "    *   **ì •ì„œ:** (ë¬¸ì„œ ë‚´ì— ìƒì„¸ ì •ë³´ëŠ” ì—†ìŒ)\n",
      "    *   **ê°™ì´ ë³´ê¸°:** (ê°ì •ì´ì…, ê°ì • ëŒ€ë¦½, ê°ì •ê³¼ ê¸°ì–µ, ê°ì •ê³¼ ë¬¸í™”, ìì¡´ê°)\n",
      "    *   **ê°ì£¼:**  ë„¤ì´ë²„ êµ­ì–´ì‚¬ì „, ì¤‘ìš©, ì²­ì¶˜ì‹¬ë¦¬í•™, ì—¬ì„±ê°€ì¡±ë¶€\n",
      "\n",
      "**ì¶”ê°€ ì •ë³´:**\n",
      "\n",
      "*   ë¬¸ë§¥ì€ \"ê°ì •\"ì´ë¼ëŠ” ì£¼ì œì— ëŒ€í•œ ì‹¬ë¦¬í•™ì  íƒêµ¬ë¥¼ ìœ„í•œ ê°œìš”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
      "*   ë‹¤ì–‘í•œ ì‹¬ë¦¬í•™ì  ì´ë¡ (ì˜ˆ: ê°ì •ì´ì…, ê°ì • ëŒ€ë¦½, ê°ì •ê³¼ ê¸°ì–µ ë“±)ì„ ë‹¤ë£¨ëŠ” ê²ƒì„ ì•”ì‹œí•©ë‹ˆë‹¤.\n",
      "*   \"ê°ì •\" ê´€ë ¨ ë‹¤ì–‘í•œ ìë£Œ(ì‚¬ì „, ë…¼ë¬¸, ìœ¡ì•„ ì •ë³´ ë“±)ë¥¼ ì°¸ê³ í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ë‹µë³€: ìŠ¬í””ì€ ê°ì • ì¤‘ì—ì„œ íŠ¹íˆ ì¤‘ìš”í•˜ê²Œ ë‹¤ë£¨ì–´ì§€ëŠ” ê°ì •ìœ¼ë¡œ, ê°œì¸ì´ ì‹¬ë¦¬ì ìœ¼ë¡œ ë¶€ì •ì ì¸ ê°ì •ë“¤ì„ í•´ì†Œí•˜ëŠ” ì¹´íƒ€ë¥´ì‹œìŠ¤ì  ì—­í• ë¿ë§Œ ì•„ë‹ˆë¼ ìŠ¬í”ˆ íƒ€ì¸ì—ê²Œ ì—°ë¯¼ì„ ì¤„ ìˆ˜ ìˆê³  ìê¸° ìì‹ ì˜ ìŠ¬í””ì— ëŒ€í•´ íƒ€ì¸ì—ê²Œì„œ ì—°ë¯¼ì„ ë°›ì„ ìˆ˜ ìˆëŠ” ì‚¬íšŒì  ì¡´ì¬ë¡œì„œ ì„œë¡œê°„ì— ê· í˜•ì„ ê°–ê²Œí•´ì£¼ëŠ” ìˆœê¸°ëŠ¥ì ì¸ ë©´ë„ ìˆë‹¤.\n",
      "\n",
      "ë‹µë³€: ì œê³µëœ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°ì •ì˜ ì¢…ë¥˜ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "*   **ìŠ¬í””**\n",
      "*   **ì •ì„œ** (ê°ì •ì˜ ì¼ë°˜ì ì¸ ë²”ì£¼)\n",
      "\n",
      "ë˜í•œ, ìë£Œì—ëŠ” ê°ì •ì˜ ì¢…ë¥˜ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‚˜ì—´ì€ ì—†ì§€ë§Œ, ê°ì • ì´ì…, ê°ì • ëŒ€ë¦½, ê°ì •ê³¼ ê¸°ì–µ, ê°ì •ê³¼ ë¬¸í™”, ìì¡´ê° ë“±ì˜ ê°œë…ë“¤ì´ ê´€ë ¨ë˜ì–´ ìˆìœ¼ë©°, ì´ëŠ” ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ê°ì •ì„ í¬ê´„í•˜ëŠ” ê²ƒìœ¼ë¡œ í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# Prompt í…œí”Œë¦¿ ì •ì˜\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "# 7. Ollama Llama3 ëª¨ë¸ ì„¤ì •\n",
    "# Ollamaì˜ LLMì„ LangChainê³¼ í†µí•©í•˜ê¸° ìœ„í•´ ì»¤ìŠ¤í…€ LLM í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Optional\n",
    "\n",
    "class OllamaLLM(LLM):\n",
    "    model_name: str = \"gemma3:4b\"\n",
    "    temperature: float = 0.0\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[list] = None) -> str:\n",
    "        response = ollama.chat(model=self.model_name, messages=[{'role': 'user', 'content': prompt}])\n",
    "        return response['message']['content']\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self):\n",
    "        return \"ollama\"\n",
    "\n",
    "# LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "llm = OllamaLLM(model_name=\"gemma3:4b\", temperature=0.0) # temperature ê°€ ì‘ìœ¼ë©´ ëª¨ë¸ì˜ ëŒ€ë‹µ ë‹¤ì–‘ì„±ì´ ì ê³ , ë†’ìœ¼ë©´ ëŒ€ë‹µì„ ë‹¤ì–‘í•˜ê²Œ ë‚´ë±‰ìŒ\n",
    "\n",
    "\n",
    "# Retriever ì„¤ì •\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})  # ìƒìœ„ 5ê°œì˜ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "\n",
    "# LLMChain ì„¤ì •\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "\n",
    "def rag_chain(question):\n",
    "    # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
    "    retrieved_docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "    # ê´€ë ¨ìˆëŠ” ë¬¸ì„œì˜ ë‚´ìš©ì„ ë‰´ë¼ì¸ ê¸°ì¤€ìœ¼ë¡œ concatenate í•¨ ì´ê±¸ ëª¨ë¸í•œí…Œ contextë¡œ ì „ë‹¬í•´ì„œ ë‹µë³€ì„ ê°€ì ¸ì˜¬ ê²ƒì´ë‹¤.\n",
    "    formatted_context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "\n",
    "    # Promptì— ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í•˜ì—¬ ë‹µë³€ ìƒì„±\n",
    "    answer = llm_chain.run({\"context\": formatted_context, \"question\": question})\n",
    "    return answer\n",
    "\n",
    "# ì¸í„°ë™í‹°ë¸Œí•˜ê²Œ ì§ˆë¬¸í•˜ê³  ì‘ë‹µ ë°›ê¸°\n",
    "print(\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. ì¢…ë£Œí•˜ë ¤ë©´ 'exit'ì„ ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "\n",
    "while True:\n",
    "    question = input(\"ì§ˆë¬¸: \")\n",
    "    if question.lower() == 'exit':\n",
    "        print(\"í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        break\n",
    "    answer = rag_chain(question)\n",
    "    print(f\"ë‹µë³€: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG ì½”ë“œë¥¼ ì“°ê³  ì‹¶ë‹¤ë©´,\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ ì„ ì •\n",
    "# llm ëª¨ë¸ ì„ ì •\n",
    "# PDF ë§Œë“¤ê¸°"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast_langch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
